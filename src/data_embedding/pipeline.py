# src/recomind/data_embedding/pipeline.py

from .database_scanner import DatabaseScanner
from .description_generator import DescriptionGenerator
from .vector_store import VectorStore
# Import the new api_client and the clean config
from ..shared import api_client, config
from . import embedding_config 

def run_ingestion_pipeline():
    """
    The main function that orchestrates the entire ingestion process.
    """
    print("--- Starting Ingestion Pipeline ---")
    
    # Step 1: Explicitly call the API to fetch settings
    source_settings = api_client.fetch_source_db_settings()

    if not source_settings:
        print("Pipeline aborted: Failed to fetch database connection settings from the API.")
        return
    
    # Step 2: Save the fetched settings for auditing
    print("Attempting to save the fetched settings for audit...")
    api_client.save_settings_to_db(source_settings)

    print(f"DEBUG: Company ID {source_settings['company_id']} settings loaded successfully.")
    print(f"DEBUG: API Key Loaded✅" if embedding_config.OPENROUTER_API_KEY else "DEBUG: API Key Missing❌")
    
    # Step 3: Pass the settings dictionary to the components that need it
    scanner = DatabaseScanner(db_settings=source_settings)
    tables_data = scanner.scan_tables()

    if not tables_data:
        print("Pipeline aborted: No table data was found by the scanner.")
        return

    generator = DescriptionGenerator()
    # Pass the full settings dictionary to the generator
    data_with_descriptions = generator.generate_for_tables(tables_data, source_settings)

    if not data_with_descriptions:
        print("Pipeline aborted: No descriptions were generated by the LLM.")
        return

    vector_db = VectorStore()
    vector_db.save(data_with_descriptions)

    print("\n--- Ingestion Pipeline Completed Successfully! ---")


if __name__ == "__main__":
    run_ingestion_pipeline()